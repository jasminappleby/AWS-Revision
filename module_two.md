
# EC2

- Highly Flexible
- Cost-effective
- Quick
- Can be closed instantly when you finish running a workload

Computer as a Service (CaaS) model 

EC2 provides _secure, resizable_ compute capacity in the cloud as EC2 instances. 

IOPS (Input/Output Operations Per Second) is a metric used to measure the performance of a storage device.

### Launch 

- Select a template with basic configurations (OS, Application Server or Applications)
- Select instance type (Specific hardware configuration)
- Select security settings to manage the in and outgoings of your network traffic

### Connect

- Can connect in different ways
- Your applications and programs will have multiple different methods to connect to directly to the instance to exchange data. 
- Users can also connect by logging in and accessing the desktop.

### Use

- After you have connected, you can use the instance. 
- You can run commands to install software, add storage, copy and organise files, and more. 

EC2 Instance Types are optimised for different uses. Consider your EC2 uses and requirements.

## General Purpose Instances

- Provide a balance of compute, memory and networking capabilites.
- Can be used in a variety of workloads (Application servers, gaming servers, backend servers for enterprise applications, small and medium databases)

## Memory Optimised Instances

- Designed to deliver fast performance that process large datasets in memory
- Good for procressing large amooutns of unstructured data or for high performance databases

## Accelerated Compute Instances

- Uses hardware accelerators or coprocessors, to perform functions more efficiently than is possible in software running on CPUs
- Floating point number calculations, graphics processing, graphic applications, game streaming and data pattern matching

## Storage Optimised Instances

- Designed for workloads that require high sequential read and write access to large datasets on local storage.
- Examples include distributed file systems, data warehousing applications, and high-frequency online transaction processing
-  Designed to deliver tens of thousands of low-latency, random IOPS to applications
- Input operation example is data entered into a system
- Output operation example is data generated by a server, like analystics performed on the records in a database
- If you have an application with a high IOPS requirement, a storage optimised instance can provide a better performance over other instance types not optimised for this type of usecase

# Pricing

## On-Demand Pricing

- Short-term, irregular workloads that cannot be intrupted
- No upfront costs or minimum contracts apply
- They run continously until you stop them
- You only pay for the compute time used
- Not recommended for use of over a year

## Amazon EC2 Savings Plan

- 1-year or 3-year plans
- Commit to a consistent amount of compute usage
- Savings of up to 72% on Demand Instances
- Anything used above the agreed usage plan is charged at an On-Demand rate. Anything below is charged at the Savings Plan rate.
- AWS Cost Explorer can help you analyse your usage over the past 7, 30 or 60 days

## Reserved Instances

- A billing discount applied to the use of On-Demand Instances
- You can purchase _Standard Reserved_ or _Convertible Reserved_ instances for a 1-year or 3-year term, or a _Scheduled Reserved_ instance for a 1-year term
- At the end of a reserved Instance term, you can still use the EC@ instance without interruption, however you are charged On-Demand rates until you do one of the following: 
    - Terminate the instance   
    - Purchased a new Reserved Instance that matches your instance attributes (instance type, region, tenancy, and platform)

## Spot Instances

- Ideal for workloads with flexible start and end times, or can withstand interruptions
- Use unused EC2 computing capacity and offer up to 90% savings off of On-Demand Instances
- Good for background processing jobs you can start and stop as needed (data processing job for customer survey)
- If you make a Spot request and there is EC@ capacity available, your Spot Instance will launch. However, if there is no capacity available, your request will not be accepted until a capacity is available
- You may find that if demand increases for EC2 computing capacity, your Spot Instance might get interrupted 

## Dedicated Hosts

- Physical servers with EC2 instance capacity that is fully dedicated to your use
- Can use your existing per-socket, per-core or per-VM software licenses to help maintain license compliance
- You can purchase _On-Demand Dedicated Hosts_ or _Dedicated Host Reservations_
- Most expensive

# Scalability

- Involves beginnign with only the resources you need and designing your architecture to automatically respond to changing demand by scaling out or in
- You only pay for the resourses you use, and don't have to worry about a lack of computing capacity to meet your customers needs
- You would use _Amazon EC2 Auto Scaling_ which will make the scaling process happen automatically

# Amazon EC2 Auto Scaling

- If a webpage is frequently timing out, it might have received more requests then it can handle
- Enables you to automatically add/remove EC2 instances in response to changing application demand
- Maintain a greater sense of application availability
- _Dynamic Scaling_ and _Predictive Scaling_
- Dynamic Scaling responds to changing demand
- Predictive Scaling automatically schedules the right number of EC2 Instances based on predicted demand
- You can add new instances to the application when necessary and terminate them when no longer needed
- To use an Auto Scaling group, you might set the minumum number of EC2 instances running to one, so at all times, there must be at least one EC2 instance running. 

## Setting up an EC2 Auto Scaling group

- A minimum capacity is the number of instances that launch immediately after you have created the Auto Scaling group. 
- You can set the desired capacity at two EC2 instances even though your application needs a minimum of one (If you do not set this, it will default to the minimum amount of instances you set)
- Maximum capacity can be set to a maximum of four. 


# Elastic Load Balancer

- An AWS service that automatically distributes incoming application traffic across multiple resource, such as EC2 instances

A load balancer acts as a single point of contact for all incoming web traffic to your Auto Scaling group. You can add/remove EC2 instances in response to the amount of incoming traffic, these requests route to the load balancer first. These requests will spread across multiple resources that will handle them. 

If you have multiple EC2 instances, an ELB distributes the workload across the multiple instances to that no single instance has to carry the bulk of it. 

Although Elastic Load Balancing and Amazon EC2 Auto Scaling are separate services, they work together to help ensure that applications running in Amazon EC2 can provide high performance and availability. 

## Low-demand period

You havw a few customers that have come to the coffee shop and are waiting to make an order. 
If only a few cash registers are open, then this would match the demand of the customers who want to make an order. 
The coffee shop is less likely to have open cash registers if the coffee shop does not have any customers. The staff will be focusing on other things. 
The cash registers in this example are equivalent to an EC2 instance. 

## High-demand period
Throughout the day, as the number of customers increase. The shop will open more cash registers to accomodate for the additional demand. 

In addition to opening more cash registers, an employee will direct customers to an appropriate cash register so the customers can be evenly distributed and served at an equal rate. Therefore, it does not overload one cash register. The employee doing the customer distribution can be seen as the Loac Balancer in this case.


# Monolithic Applications and Microservices

## Monolithic Applications

- Apps are made of multiple components that communicate with each other to transmit data, fulfill requests and keep the app runnning. 
- If you have an app with tightly coupled components, these components might include databases, servers, UI, business logic, etc. This type of architecture can be considered a monolithic application. 
- If a single component fails, the other components will fail. Therefore, the entire app can fail.

## Microservices

- Help maintain application availability when a single component fails
- Applications are loosely coupled
- If a single component fails, the other components continue to work because they are communicating with each other. The loose coupling prevents the entire application from failing. 
- When designing applications on AWS, you can take a microservices approach with services and components that fulfill different functions. (Amazon Simple Notification Service (Amazon SNS) and Amazon Simple Queue Service (Amazon SQS))

# Amazon Simple Queue Service (Amazon SQS)

- Amazon Simple Queue Service is a message queuing service
- You can send, store and receive messages between software components, without losing messages or requiring other services to be available
- An app sends messages into a queue, and a user or service retrieves a message from the queue, processes it and then deletes it from the queue. 
- A message service such as SQS enables messages between decoupled application components

An example of NOT using SQS: 

1. A cashier takes an order and writes it on a piece of paper
2. Cashier delivers the paper to the barista
3. Barista makes the drink and gives the drink to the customer
4. Order repeats when the next order comes in. This process can only work if both the cashier and barista are co-ordinated

If a staff member is on a break, this process would stop until the staff member comes back from their break. This would cause the customer to be waiting for the staff members to come back. As the shop gets busier daily, the process becomes slower. A queue process could be beneficial here. 

An example of using SQS:

1. A cashier takes an order from a customer
2. Cashier places the order into a queue
3. The queue serves as a buffer between a cashier and the barista
4. If the barista is busy or on break, the cashier can continue placing orders and placing them into a queue
5. The barista will check the queue and retrieve the first (oldest) order
6. The barista will prepare the drink and give it to the customer
7. The barista will remove the completed order from the queue and start working on the next order in the queue
8. Whilst the barista is getting through the queue, the cashier will continue to take order and add to the queue

# Amazon Simple Notification Service (Amazon SNS)

- A public/subscribe service
- Using Amazon SNS topics, a publisher can publish messages to subscribers

# Serverless Computing

If you want to run applications in EC2, you must provsion instances (virtual servers), upload your code, continue to manage the instances while your app is running.

The term _"serverless"_ means that your code runs on servers, but you do not need to provision or manage these servers.  

## Benefits to Serverless Computing

- Allows you to focus on innovating new products and features instead of maintaining servers.
- Flexibility to scale serverless apps automatically
- Can adjust apps capacity by modifying the units of consumptions, such as throughput and memory

# AWS Lambda

AWS Lambda would be an example of serverless computing. It is a service that lets you run code without needing to provision or manage servers. 

- You only use the compute time you consume.
- Charges apply only when your code is running.
- You can run code for virtually any type of app or backend service, all with zero admin
- A simple lambda function might involve automatically resizing uploaded images to the AWS Cloud. In this case, the function triggers when uploading a new image.

## How Lambda Works

1. Upload your code to Lambda
2. You set your code to trigger from an event source, such as AWS services, mobile apps or HTTP endpoints
3. Lambda runs your code only when triggered
4. You pay only for the compute time that you use. 

# Containers

- Build and run containerised applications/
- Containers can provide you with a standard way to package your apps code and dependencies into a single object
- You can also use containers for processes and workflows in wihch there are essential requirements for security, reliability and scalability

## One host with multiple containers
- Assume that a companies app dev has an env on their computer that is different from the env on the computers used by the IT operations staff. 
- The dev wants to ensure that the apps env remains consistent regardless of deployment, so they use a containerised approach. 
- This helps to reduce time spent debugging apps and diagnosing differences in computing envs. 

## Tens of hosts with hundreds of containers

- Consider scalability
- Assume you manage tens of hosts with hundreds of containers.
- Alternatively, you have to manage possibly hundreds of hosts with thousands of containers.At a large scale, imagine how much time it might take for you to monitor memory usage. security, logging and so on. 

# Amazon Elastic Container Service (Amazon ECS)

- Highly scalable, high-performance container management system that enables you to run and scale containerized applications on AWS. 

# Amazon ECS supports Docker containers. 

- Docker is a software platform that enables you to build, test, and deploy applications quickly. 
- AWS supports the use of open-source Docker Community Edition and subscription-based Docker Enterprise Edition. With Amazon ECS, you can use API calls to launch and stop Docker-enabled applications.